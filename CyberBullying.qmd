---
title: "Cyberbullying"
format: html
author: 
  - name: Audrey Saidel
    email: audrey.saidel@snhu.edu
    affiliations: 
      - name: Southern New Hampshire University
date: 3/19/2025
date-modified: 3/19/2025
title-block-banner: "#F9629F"
description: "Cyberbullying Text Analysis"
theme: journal
toc: true
execute:
  freeze: auto
code-fold: true
---
# Setup
```{r}
library(tidyverse)
library(tidymodels)
library(tidytext)

data <- read_csv("https://raw.githubusercontent.com/agmath/agmath.github.io/refs/heads/master/data/classification/cyberbullying_tweets.csv")

data <- data |>
  distinct() 

set.seed(355)
data_splits <- initial_split(data, prop = 0.85)

train <- training(data_splits)
test <- testing(data_splits)
```


```{r}
train |>
  head()
```

## Tokenizaation
```{r}
common_words_list <- train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", 
                       "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  count(word) |>
  arrange(-n) |>
  filter( n >= 100) |>
  pull(word)

train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", 
                       "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  filter(word %in% common_words_list)|>
distinct() |> ## Get rid of multiple WORDS in a tweet
  slice(1:1e4) |> ## First 10000 rows
 mutate(
   present = 1
 ) |>
  pivot_wider(id_cols = c(cyberbullying_type, tweet_id),
              names_from = word, 
              values_from = present)

```
## Data Visualization

```{r}
train |>
  mutate(tweet_id = row_number()) |>
  unnest_tokens(word, tweet_text) |>
  anti_join(stop_words) |>
  filter(!(word %in% c("http", "https", "t.co", "bully", 
                       "bullies", "bullied"))) |>
  filter(!str_starts(word, "\\d+")) |>
  group_by(cyberbullying_type) |>
  count(word) |>
  top_n(15, n) |>
  ungroup() |>
  ggplot() +
  geom_bar(aes(x = word, y = n, fill = cyberbullying_type),
           stat = "identity", color = "black") +
          facet_wrap(~cyberbullying_type, scales = "free") + 
          coord_flip()

```
```{r}
p <- train %>%
  #filter(str_detect(cyberbullying_type, "gender") | str_detect(cyberbullying_type, "ethnicity"))
  filter((cyberbullying_type == "gender") | (cyberbullying_type == "ethnicity")) %>%
  unnest_tokens(word, tweet_text) %>%
  anti_join(stop_words) %>%
  filter(!(word %in% c("http", "https", "t.co", "bully",
                       "bullies", "bullied"))) %>%
  filter(!str_starts(word, "\\d+")) %>%
  group_by(cyberbullying_type) %>%
  count(word) %>%
  filter(n > 25) %>%
  pivot_wider(names_from = cyberbullying_type, values_from = n) %>% 
  mutate(
    ethnicity = ifelse(is.na(ethnicity), 0, ethnicity),
    gender = ifelse(is.na(gender), 0, gender),
  ) %>%
  ggplot() + 
  geom_text(aes(x = ethnicity, y = gender, label = word)) + 
  geom_abline(linetype = "dashed")

plotly::ggplotly(p)  
```
Gender and ethnicity comparison above.
## Regular Expressions
Working to extract Hashtags and Mentions
```{r}
train %>%
  mutate(
    hashtags = str_extract(tweet_text, "#([A-z]|\\d|-)+"),
    mentions = str_extract(tweet_text, "@([A-z]|\\d|-)+")
  ) %>%
  filter(!is.na(hashtags) | !is.na(mentions))
```
Every tweet is repeated the amount of times it had a hashtag and mention
```{r}
 train %>%
  mutate(
    hashtags = str_extract_all(tweet_text, "#([A-z]|\\d|-)+"),
    mentions = str_extract_all(tweet_text, "@([A-z]|\\d|-)+")
  ) %>%
  filter((lengths(hashtags) > 0) | (lengths(mentions) > 0)) %>%
  unnest(mentions) %>%
  unnest(hashtags)
```
Counting hashtags and mentions.

```{r}
train %>%
  mutate(
    hashtags = map_chr(str_extract_all(tweet_text, "#([A-z]|\\d|-)+"), ~ paste(.x, collapse = ", ")),
    mentions = map_chr(str_extract_all(tweet_text, "@([A-z]|\\d|-)+"), ~ paste(.x, collapse = ", "))
  ) %>%
  filter((hashtags != "") | (mentions != "")) %>%
  mutate(
    hashtag_count = str_count(hashtags, ",") + 1,
    mention_count = str_count(mentions, ",") + 1,
  )
```

